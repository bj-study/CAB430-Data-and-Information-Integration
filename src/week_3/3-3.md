# 3.3: ETL

## Data Acquisition and Integration
Data acquisition and integration is a process undertaken to populate a data warehouse.

There are three main parts to the process:
1. **Extract**: Retrieve data in a source system to produce a new set of source data
2. **Transform**: Inspect, clean, and conform the new source data into the data warehouse
3. **Load**: Update the data warehouse by adding the new transformed data

The ETL process begins by identifying a data source and the data inside that we
are interested in. Along with the data source, we need to know the target system,
the destination where the data is loading into.

Data transformation may need to occur, for example, we may need to convert `"True"` 
and `"False"` to `0` and `1`.

## Source System Analysis
Soure system analysis provides insight and understanding of the enterprise data
for a data warehouse. In this stage, the focus should be on the enterprise source data
and its analysis.

The data warehouse designer must be able to query and survey the enterprise data,
not just a sumarry or description of it.

When analysing the source system, a data warehouse designer may look for the following
things:
- Multiple systems of data
- Entity data including physical and logical members, agents, facilities, and resources
- Transaction data, also known as event data, used to identify the moment when an
enterprise performs its primary functions

### Data Profile
Once a source system analysis has been performed, a data profile is created. It
provides information about:
- Where data is stored
- What is stored
- How the data is grouped
- How the data entities relate to each other

A data profile may contain the following headers:
- Data Stores: A list of physical hardware on which the enterprise places its data
- Data entities: Enterprise entities that were identified
- Data elements: The data elements stored in the data stores and details about the data
elements, e.g. name, format, domain of values, etc.
- Data model: The logical or physical models within the source system. Logical models
indicate the business understanding and meaning of data while physical models indicate
the data structures, how the data is stored physically

Tables can be used to describle the details of each identified entity

| Element Name | Datatype | Format | Not null values | Minimum | Maximum | ... |
|--|--|--|--|--|--|--|
| Birthday | Date | ddmmyyyy | null | 01011950 | 31122010 | |
| Phone Number | String | (##) #### #### | Not null |  |  | |
| ... |  |  |  |  |  | |

### Business Rlues
Business rules are used to govern the data within the source system.

For example, the business rules:
- Intra-record business rules: Only apply to a single column, e.g. Column A + Column B = Column C
- Intra-dataset business rules: Only apply to a single dataset (i.e. a table), e.g. Row 1. Column A + Row 2. Column A = Row 3. Column B
- Cross dataset business rules: Cross sets of data within a source system, e.g. File1. Column A = Table 2. Column B

## Target System Analysis
Once a source system analysis has been undertaken, a target system analysis is done.
Target system analysis is used to identify and document expectations of the data within
a data warehouse:
- Clarify the expectations of the data warehouse designer
- Clarify the expectations of the data warehouse Customers
- Recognise and resolve discrepancies in the expectations between the data warehouse
designer and customers

### ETL Direct Requirements
Direct requirements are the explicit expectations from data warehouse customers.
It's the ETL developers job to understand the customers expectations and pass
any anomalies back to the data warehouse designer for resolution.

### Data Profile of the Target System
Once a target system analysis has been performed, a data profile is created. It
provides information about:
- Data entities: Identified enterprise entites
- Data elements: The data elements to be stored within the data warehouse and some
details about the data elements, e.g. name, format, domain of values, etc.
- Data model of the source system: Logic and physical models

## Data Transformation Approaches
There are two main ways to approach the ETL Process:
1. Traditional approach (ETL)
    1. Data is extracted from a source system
    2. A transform performs all data modifications to the source data
    3. A load application reads the transformed data and performs the necessary inserts,
    updates, and deletes to the destination data warehouse
2. Alternative approach (ELT)
    1. Data is extracted from a source system
    2. A load application loads the data into the data warehouse
    3. Then performs all the transformation functions on the data warehouse platform
    updating all the data in the data warehouse.

In an ETL application, data transformation is done in a stagin database using
specific software tools such as integration services in SQL Server. After that,
the transformed data is loaded into the data warehouse.

This method guarantees that only relevant data is extracted and processed leading to
reduced development, extraction, and processing overhead. Accounting only for relevant
data implies that future requirements may need data not included in the original
design which could lead to re-development to add the required data to the warehouse.
An additional stage is also required to master the required tools.

IN an ELT process, data is extracted from the data sources into the database where
transformations then take place. The extraction and loading are isolated from
the transformation process allowing the inclusion of data that may be needed in the
future.

The ELT performs transformations using a traditional database engine and, given the
large data volumes and complexity, could adversely affect the quality of data.
